{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset from the CSV file. Adjust the file path as needed.\n",
    "df = pd.read_csv(\"malicious_phish.csv\")\n",
    "\n",
    "# We assume df has columns: 'url' and 'type' (e.g., \"benign\", \"defacement\", \"phishing\").\n",
    "# We'll create a binary label: 0 for benign, 1 for anything else.\n",
    "df = df[df['type'] == 'benign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import string\n",
    "\n",
    "def generate_dummy_url():\n",
    "    domain = ''.join(random.choices(string.ascii_lowercase, k=8))\n",
    "    return f\"http://{domain}.com\"\n",
    "\n",
    "def generate_realistic_url():\n",
    "    # Lists of components to create realistic-looking URLs\n",
    "    protocols = ['http://', 'https://']\n",
    "    tlds = ['.com', '.org', '.net', '.ru', '.us', '.co', '.site', '.app']\n",
    "    file_extensions = ['.php', '.html', '.aspx', '']\n",
    "    path_patterns = [\n",
    "        'checkpoint/login',\n",
    "        'images/secure',\n",
    "        'admin/panel',\n",
    "        'verify/account',\n",
    "        'secure/login',\n",
    "        'manager/auth'\n",
    "    ]\n",
    "    \n",
    "    # Generate random components\n",
    "    protocol = random.choice(protocols)\n",
    "    \n",
    "    # Create domain (might include subdomain)\n",
    "    if random.random() < 0.3:  # 30% chance of subdomain\n",
    "        subdomain = ''.join(random.choices(string.ascii_lowercase, k=random.randint(2, 8)))\n",
    "        domain = f\"{subdomain}.\"\n",
    "    else:\n",
    "        domain = \"\"\n",
    "    \n",
    "    # Main domain name\n",
    "    domain += ''.join(random.choices(string.ascii_lowercase + string.digits, k=random.randint(6, 12)))\n",
    "    \n",
    "    # TLD\n",
    "    tld = random.choice(tlds)\n",
    "    \n",
    "    # Build the base URL\n",
    "    url = f\"{protocol}{domain}{tld}\"\n",
    "    \n",
    "    # Add path and parameters (70% chance)\n",
    "    if random.random() < 0.7:\n",
    "        # Random path\n",
    "        if random.random() < 0.5:\n",
    "            path = random.choice(path_patterns)\n",
    "        else:\n",
    "            path = ''.join(random.choices(string.ascii_lowercase + string.digits, k=random.randint(4, 12)))\n",
    "        \n",
    "        # Add file extension\n",
    "        path += random.choice(file_extensions)\n",
    "        \n",
    "        url += f\"/{path}\"\n",
    "        \n",
    "        # Add query parameters (30% chance)\n",
    "        if random.random() < 0.3:\n",
    "            params = []\n",
    "            num_params = random.randint(1, 3)\n",
    "            param_names = ['id', 'session', 'token', 'auth', 'cmd', 'user']\n",
    "            for _ in range(num_params):\n",
    "                param_name = random.choice(param_names)\n",
    "                param_value = ''.join(random.choices(string.ascii_letters + string.digits, k=random.randint(16, 32)))\n",
    "                params.append(f\"{param_name}={param_value}\")\n",
    "            url += '?' + '&'.join(params)\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_size = int(2 * 10**6) # Same as phishin dataset size\n",
    "dummies = [generate_realistic_url() for _ in range(desired_size - df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the dummy URLs\n",
    "dummy_df = pd.DataFrame({\n",
    "    'url': dummies,\n",
    "    'type': 'benign'\n",
    "})\n",
    "\n",
    "# Concatenate the original DataFrame with the dummy DataFrame\n",
    "df = pd.concat([df, dummy_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the entire dataset\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split into two DataFrames\n",
    "df_1_4M = df.iloc[:1400000]  # First 1.4M rows\n",
    "df_remaining = df.iloc[1400000:]  # Remaining rows\n",
    "\n",
    "# Print statistics\n",
    "print(f\"First DataFrame size: {len(df_1_4M)}\")\n",
    "print(f\"Second DataFrame size: {len(df_remaining)}\")\n",
    "print(f\"Total URLs: {len(df)}\")\n",
    "\n",
    "# Save both DataFrames to CSV files\n",
    "df_1_4M.to_csv('benign_urls_1_4M.csv', index=False)\n",
    "df_remaining.to_csv('benign_urls_remaining.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remaining.to_csv('negative_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1_4M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the phishing links from the file\n",
    "with open('phishing_links.lst', 'r') as file:\n",
    "    phishing_links = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "# Create a DataFrame for phishing links\n",
    "phishing_df = pd.DataFrame({\n",
    "    'url': phishing_links,\n",
    "    'type': 'phishing'\n",
    "})\n",
    "\n",
    "# Combine with the benign URLs\n",
    "full_dataset = pd.concat([df, phishing_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "full_dataset = full_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save the combined dataset to CSV\n",
    "full_dataset.to_csv('full_dataset.csv', index=False)\n",
    "\n",
    "print(f\"Full dataset created with {len(full_dataset)} URLs\")\n",
    "print(f\"Phishing URLs: {len(full_dataset[full_dataset['type'] == 'phishing'])}\")\n",
    "print(f\"Benign URLs: {len(full_dataset[full_dataset['type'] == 'benign'])}\")\n",
    "print(\"Dataset saved to 'full_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"negative_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(test[\"type\"] == \"benign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "t = pd.read_csv(\"full_dataset.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
